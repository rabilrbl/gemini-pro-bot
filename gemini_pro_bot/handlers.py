import asyncio

# import logging
from fly_log import debug_print as print
from gemini_pro_bot.llm import model, img_model
from google.generativeai.types.generation_types import (
    StopCandidateException,
    BlockedPromptException,
    BrokenResponseError,
)
from telegram import Update
from telegram.ext import (
    ContextTypes,
)
from telegram.error import NetworkError, BadRequest
from telegram.constants import ChatAction, ParseMode
from gemini_pro_bot.html_format import format_message
import PIL.Image as load_image
from io import BytesIO


def new_chat(context: ContextTypes.DEFAULT_TYPE) -> None:
    context.chat_data["chat"] = model.start_chat()


async def start(update: Update, _: ContextTypes.DEFAULT_TYPE) -> None:
    """Send a message when the command /start is issued."""
    user = update.effective_user
    await update.message.reply_html(
        f"–ü—Ä–∏–≤–µ—Ç, {user.mention_html()}!\n\n–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–æ—Ç—É –Ω–∞—á–∏–Ω–∞—è —Å–æ —Å–ª–æ–≤–∞ ¬´–≥–ø—Ç¬ª, —á—Ç–æ–±—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç. –ù–∞–ø—Ä–∏–º–µ—Ä: ¬´–≥–ø—Ç, –∫–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–≤–∞—Ä–∏—Ç—å —è–π—Ü–æ?¬ª\n\n–û—Ç–ø—Ä–∞–≤—å—Ç–µ /help, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ø–æ–º–æ—â—å.",
        # reply_markup=ForceReply(selective=True),
    )


async def help_command(update: Update, _: ContextTypes.DEFAULT_TYPE) -> None:
    """Send a message when the command /help is issued."""
    help_text = """
<b>–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:</b>
/start ‚Äî –∑–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞
/help ‚Äî –ø–æ–ª—É—á–∏—Ç—å –ø–æ–º–æ—â—å. –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ

<b>–ö–æ–º–∞–Ω–¥—ã —á–∞—Ç–∞:</b>
/new ‚Äî –Ω–∞—á–∞—Ç—å –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é —á–∞—Ç–∞ (–º–æ–¥–µ–ª—å –∑–∞–±—É–¥–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç).

–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–æ—Ç—É –Ω–∞—á–∏–Ω–∞—è —Å–æ —Å–ª–æ–≤–∞ ¬´–≥–ø—Ç¬ª, —á—Ç–æ–±—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç. –ù–∞–ø—Ä–∏–º–µ—Ä: ¬´<code>–≥–ø—Ç –∫–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–≤–∞—Ä–∏—Ç—å —è–π—Ü–æ?</code>¬ª
"""
    await update.message.reply_html(help_text)


async def newchat_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Start a new chat session."""
    init_msg = await update.message.reply_text(
        text="–ó–∞–±—ã–≤–∞—é –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç...",
        reply_to_message_id=update.message.message_id,
    )
    new_chat(context)
    await init_msg.edit_text("–ù–æ–≤–∞—è —Å–µ—Å—Å–∏—è –Ω–∞—á–∞—Ç–∞, –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–±—ã—Ç.")


# Define the function that will handle incoming messages
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handles incoming text messages from users.

    Checks if a chat session exists for the user, initializes a new session if not.
    Sends the user's message to the chat session to generate a response.
    Streams the response back to the user, handling any errors.
    """
    if context.chat_data.get("chat") is None:
        new_chat(context)
    text = update.message.text
    words = text.split()

    if words:
        if words[0].lower() != "–≥–ø—Ç":
            return

    print("User: ", update.message.from_user.username, " Message:", text)

    try:
        await context.bot.send_message(
            chat_id=-1001201930449,
            text=f"<b>user</b>: @{update.message.from_user.username}\n<b>message</b>: {text}\n<b>chat</b>: {update.message.chat.title or 'direct'}",
            parse_mode="HTML",
        )
    except BadRequest:
        print("Error sending message to log channel")
        return

    # logging.info(f"User: {update.message.from_user.username} Message: {text}")
    init_msg = await update.message.reply_text(
        text="–î—É–º–∞—é –Ω–∞–¥ –æ—Ç–≤–µ—Ç–æ–º...", reply_to_message_id=update.message.message_id
    )

    if update.message.from_user.id == 487532064:
        await init_msg.edit_text("üñï")
        return

    await update.message.chat.send_action(ChatAction.TYPING)
    # Generate a response using the text-generation pipeline
    chat = context.chat_data.get("chat")  # Get the chat session for this chat
    clean_text = text.replace("–≥–ø—Ç", "").strip()
    response = None
    try:
        response = await chat.send_message_async(
            clean_text, stream=True
        )  # Generate a response
    except (BrokenResponseError, StopCandidateException) as sce:
        print("Prompt: ", text, " was stopped. User: ", update.message.from_user)
        print(sce)
        await init_msg.edit_text("The model unexpectedly stopped generating.")
        chat.rewind()  # Rewind the chat session to prevent the bot from getting stuck
        return
    except BlockedPromptException as bpe:
        print("Prompt: ", text, " was blocked. User: ", update.message.from_user)
        print(bpe)
        await init_msg.edit_text("Blocked due to safety concerns.")
        if response:
            # Resolve the response to prevent the chat session from getting stuck
            await response.resolve()
        return
    full_plain_message = ""
    # Stream the responses
    async for chunk in response:
        try:
            if chunk.text:
                full_plain_message += chunk.text
                message = format_message(full_plain_message)
                init_msg = await init_msg.edit_text(
                    text=message,
                    parse_mode=ParseMode.HTML,
                    disable_web_page_preview=True,
                )
        except StopCandidateException as sce:
            await init_msg.edit_text("The model unexpectedly stopped generating.")
            chat.rewind()  # Rewind the chat session to prevent the bot from getting stuck
            continue
        except BadRequest:
            await response.resolve()  # Resolve the response to prevent the chat session from getting stuck
            continue
        except NetworkError:
            raise NetworkError(
                "Looks like you're network is down. Please try again later."
            )
        except IndexError:
            await init_msg.reply_text(
                "Some index error occurred. This response is not supported."
            )
            await response.resolve()
            continue
        except Exception as e:
            print(e)
            if chunk.text:
                full_plain_message = chunk.text
                message = format_message(full_plain_message)
                init_msg = await update.message.reply_text(
                    text=message,
                    parse_mode=ParseMode.HTML,
                    reply_to_message_id=init_msg.message_id,
                    disable_web_page_preview=True,
                )
        # Sleep for a bit to prevent the bot from getting rate-limited
        await asyncio.sleep(0.1)


async def handle_image(update: Update, _: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle incoming images with captions and generate a response."""
    images = update.message.photo
    caption = update.message.caption

    if caption == None:
        return
    elif caption.split()[0].lower() != "–≥–ø—Ç":
        return

    print("User: ", update.message.from_user.username, " Caption:", caption)
    # logging.info(f"User: {update.message.from_user.username} Caption: {caption}")

    try:
        await _.bot.send_message(
            chat_id=-1001201930449,
            text=f"<b>user</b>: @{update.message.from_user.username}\n<b>message</b>: {caption}\n<b>chat</b>: {update.message.chat.title or 'direct'}",
            parse_mode="HTML",
        )
    except BadRequest:
        print("Error sending message to log channel")
        return

    init_msg = await update.message.reply_text(
        text="–î—É–º–∞—é...", reply_to_message_id=update.message.message_id
    )

    if update.message.from_user.id == 487532064:
        await init_msg.edit_text("üñï")
        return

    unique_images: dict = {}
    for img in images:
        file_id = img.file_id[:-7]
        if file_id not in unique_images:
            unique_images[file_id] = img
        elif img.file_size > unique_images[file_id].file_size:
            unique_images[file_id] = img
    file_list = list(unique_images.values())
    file = await file_list[0].get_file()
    a_img = load_image.open(BytesIO(await file.download_as_bytearray()))
    prompt = None
    if update.message.caption.lower() != "–≥–ø—Ç":
        prompt = update.message.caption.replace("–≥–ø—Ç", "").strip()
    else:
        # prompt = "–ò–∑—É—á–∏ –¥–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑, –æ–ø–∏—Å—ã–≤–∞—é—â–∏–π –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ, –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –≤–æ–∑–º–æ–∂–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏. –û–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —ç–ª–µ–º–µ–Ω—Ç—ã –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏, —Ü–≤–µ—Ç–æ–≤—É—é –ø–∞–ª–∏—Ç—Ä—É, —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –∞—Ç–º–æ—Å—Ñ–µ—Ä—É –∏ –ª—é–±—ã–µ –¥—Ä—É–≥–∏–µ –∑–∞–º–µ—Ç–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏. –¢–≤–æ–π –æ—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–º, –∞ —Ç–∞–∫–∂–µ –≤–∫–ª—é—á–∞—Ç—å –≤ —Å–µ–±—è –≤–∞—à–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–µ —Ç–≤–æ—Ä—á–µ—Å–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."
        prompt = "–ò–∑—É—á–∏ –¥–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é –∏ –Ω–∞–ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —ç—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É—è —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫. –£–∫–∞–∂–∏, —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ, –∫–∞–∫–∏–µ —Ü–≤–µ—Ç–∞ –∏ —Ñ–æ—Ä–º—ã –ø—Ä–µ–æ–±–ª–∞–¥–∞—é—Ç, –∫–∞–∫–æ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–ª–∏ –∞—Ç–º–æ—Å—Ñ–µ—Ä–∞ —Å–æ–∑–¥–∞—é—Ç—Å—è. –ï—Å–ª–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –µ—Å—Ç—å –ª—é–¥–∏, –∂–∏–≤–æ—Ç–Ω—ã–µ –∏–ª–∏ –ø—Ä–µ–¥–º–µ—Ç—ã, –æ–ø–∏—à–∏ –∏—Ö –≤–Ω–µ—à–Ω–∏–π –≤–∏–¥, –¥–µ–π—Å—Ç–≤–∏—è –∏ –≤–∑–∞–∏–º–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è, –≥–¥–µ —Å–¥–µ–ª–∞–Ω–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è –∏ —Ç–∞–∫ –¥–∞–ª–µ–µ. –¢–≤–æ–π –æ—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–º. –ù–µ –ø–∏—à–∏ —Å–≤–æ–µ –º–Ω–µ–Ω–∏–µ –∏–ª–∏ –æ—Ü–µ–Ω–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∞ —Ç–æ–ª—å–∫–æ —Ñ–∞–∫—Ç—ã –∏ –¥–µ—Ç–∞–ª–∏."
    response = await img_model.generate_content_async([prompt, a_img], stream=True)
    full_plain_message = ""
    async for chunk in response:
        try:
            if chunk.text:
                full_plain_message += chunk.text
                message = format_message(full_plain_message)
                init_msg = await init_msg.edit_text(
                    text=message,
                    parse_mode=ParseMode.HTML,
                    disable_web_page_preview=True,
                )
        except StopCandidateException:
            await init_msg.edit_text("The model unexpectedly stopped generating.")
        except BadRequest:
            await response.resolve()
            continue
        except NetworkError:
            raise NetworkError(
                "Looks like you're network is down. Please try again later."
            )
        except IndexError:
            await init_msg.reply_text(
                "Some index error occurred. This response is not supported."
            )
            await response.resolve()
            continue
        except Exception as e:
            print(e)
            if chunk.text:
                full_plain_message = chunk.text
                message = format_message(full_plain_message)
                init_msg = await update.message.reply_text(
                    text=message,
                    parse_mode=ParseMode.HTML,
                    reply_to_message_id=init_msg.message_id,
                    disable_web_page_preview=True,
                )
        await asyncio.sleep(0.1)
